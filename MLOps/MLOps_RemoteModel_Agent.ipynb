{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## MLOps Remote Model Monitoring Demo\n",
        "Dec. 2021 / Agent version 8.0.3\n",
        "\n",
        "<pre>raul.arrabales@datarobot.com</pre>\n",
        "\n",
        "Adapted from DataRobot Community [6.3.3 version](https://github.com/datarobot-community/custom-models/tree/master/tracking_agents/python)"
      ],
      "metadata": {
        "id": "yv4GYhcr5grV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preliminar configuration"
      ],
      "metadata": {
        "id": "KYSsXRCt6R3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chech Python version\n",
        "! python -V"
      ],
      "metadata": {
        "id": "sVkIavM3qbed",
        "outputId": "fd91d2e8-6e1d-4713-d8ee-ade00408fcff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount my google drive so I can access my config files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLbgGTUnusVC",
        "outputId": "41fdd685-dbb8-4c95-e9d6-8866e599e935"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10rwgjk0qX87"
      },
      "source": [
        "### MLOps Agent Repo Download\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tEXCmhKoqX88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d305b963-1ddd-4b97-8061-845f07fac82c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mlops-examples'...\n",
            "remote: Enumerating objects: 1407, done.\u001b[K\n",
            "remote: Counting objects: 100% (591/591), done.\u001b[K\n",
            "remote: Compressing objects: 100% (306/306), done.\u001b[K\n",
            "remote: Total 1407 (delta 244), reused 549 (delta 221), pack-reused 816\u001b[K\n",
            "Receiving objects: 100% (1407/1407), 110.26 MiB | 32.31 MiB/s, done.\n",
            "Resolving deltas: 100% (612/612), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the MLOps Examples (custom models) repository\n",
        "# The DataRobot community repo changed name from MLOps Examples to Custom Models\n",
        "! git clone https://github.com/datarobot-community/mlops-examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s5clkv8wqX8-",
        "outputId": "53f6ebac-5025-455a-8951-8422ed6873b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting attrs==19.3.0\n",
            "  Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r mlops-examples/tracking_agents/python/requirements.txt (line 3)) (0.2.0)\n",
            "Collecting boto3==1.11.4\n",
            "  Downloading boto3-1.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting botocore==1.14.4\n",
            "  Downloading botocore-1.14.4-py2.py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 21.3 MB/s \n",
            "\u001b[?25hCollecting certifi==2020.12.5\n",
            "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 43.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r mlops-examples/tracking_agents/python/requirements.txt (line 7)) (3.0.4)\n",
            "Collecting contextlib2==0.6.0.post1\n",
            "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting datarobot==2.22.1\n",
            "  Downloading datarobot-2.22.1.tar.gz (5.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1 MB 43.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from -r mlops-examples/tracking_agents/python/requirements.txt (line 10)) (4.4.2)\n",
            "Collecting deprecation==2.1.0\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting docutils==0.15.2\n",
            "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
            "\u001b[K     |████████████████████████████████| 547 kB 27.0 MB/s \n",
            "\u001b[?25hCollecting future==0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 50.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r mlops-examples/tracking_agents/python/requirements.txt (line 14)) (2.10)\n",
            "Collecting jmespath==0.10.0\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting joblib==0.17.0\n",
            "  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\n",
            "\u001b[K     |████████████████████████████████| 301 kB 43.9 MB/s \n",
            "\u001b[?25hCollecting numpy==1.19.4\n",
            "  Downloading numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 22.6 MB/s \n",
            "\u001b[?25hCollecting packaging==20.7\n",
            "  Downloading packaging-20.7-py2.py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (from -r mlops-examples/tracking_agents/python/requirements.txt (line 19)) (1.1.5)\n",
            "Collecting parso==0.7.0\n",
            "  Downloading parso-0.7.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting pika==0.13.1\n",
            "  Downloading pika-0.13.1-py2.py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 66.8 MB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 66.5 MB/s \n",
            "\u001b[?25hCollecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 62.1 MB/s \n",
            "\u001b[?25hCollecting pytz==2020.4\n",
            "  Downloading pytz-2020.4-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[K     |████████████████████████████████| 509 kB 39.1 MB/s \n",
            "\u001b[?25hCollecting PyYAML==5.3.1\n",
            "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
            "\u001b[K     |████████████████████████████████| 269 kB 52.2 MB/s \n",
            "\u001b[?25hCollecting pyzmq==20.0.0\n",
            "  Downloading pyzmq-20.0.0-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 37.7 MB/s \n",
            "\u001b[?25hCollecting requests==2.25.0\n",
            "  Downloading requests-2.25.0-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting requests-toolbelt==0.9.1\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting s3transfer==0.3.3\n",
            "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 30.4 MB/s \n",
            "\u001b[?25hCollecting scipy==1.5.4\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 69.6 MB/s \n",
            "\u001b[?25hCollecting threadpoolctl==2.1.0\n",
            "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
            "Collecting trafaret==1.2.0\n",
            "  Downloading trafaret-1.2.0-py3-none-any.whl (27 kB)\n",
            "Collecting urllib3==1.25.11\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil==2.8.1->-r mlops-examples/tracking_agents/python/requirements.txt (line 24)) (1.15.0)\n",
            "Building wheels for collected packages: datarobot, future, PyYAML\n",
            "  Building wheel for datarobot (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for datarobot: filename=datarobot-2.22.1-py3-none-any.whl size=276581 sha256=b64a29aabd0d40645169fe38721baff9f513f914edb3ae82c5d578fe26ba222e\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/8d/3a/1314534c32e2fee4628ad7e2f7b076aac4b700d55785a7e3dc\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=1560bb6dfa2c704a2a276ed901177b679372808f2dd90381bcc63ec0050dd6cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44635 sha256=913ed202a1963358f4ef15e29a19bb003d7d04a4e2d23121bc5cf93baf37e915\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n",
            "Successfully built datarobot future PyYAML\n",
            "Installing collected packages: urllib3, python-dateutil, jmespath, docutils, certifi, requests, pytz, pyparsing, numpy, botocore, trafaret, threadpoolctl, scipy, s3transfer, requests-toolbelt, PyYAML, packaging, joblib, contextlib2, attrs, scikit-learn, pyzmq, py4j, pika, parso, future, deprecation, datarobot, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2021.10.8\n",
            "    Uninstalling certifi-2021.10.8:\n",
            "      Successfully uninstalled certifi-2021.10.8\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.6\n",
            "    Uninstalling pyparsing-3.0.6:\n",
            "      Successfully uninstalled pyparsing-3.0.6\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.0.0\n",
            "    Uninstalling threadpoolctl-3.0.0:\n",
            "      Successfully uninstalled threadpoolctl-3.0.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.0\n",
            "    Uninstalling joblib-1.1.0:\n",
            "      Successfully uninstalled joblib-1.1.0\n",
            "  Attempting uninstall: contextlib2\n",
            "    Found existing installation: contextlib2 0.5.5\n",
            "    Uninstalling contextlib2-0.5.5:\n",
            "      Successfully uninstalled contextlib2-0.5.5\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.2.0\n",
            "    Uninstalling attrs-21.2.0:\n",
            "      Successfully uninstalled attrs-21.2.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 22.3.0\n",
            "    Uninstalling pyzmq-22.3.0:\n",
            "      Successfully uninstalled pyzmq-22.3.0\n",
            "  Attempting uninstall: parso\n",
            "    Found existing installation: parso 0.8.3\n",
            "    Uninstalling parso-0.8.3:\n",
            "      Successfully uninstalled parso-0.8.3\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jedi 0.18.1 requires parso<0.9.0,>=0.8.0, but you have parso 0.7.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-5.3.1 attrs-19.3.0 boto3-1.11.4 botocore-1.14.4 certifi-2020.12.5 contextlib2-0.6.0.post1 datarobot-2.22.1 deprecation-2.1.0 docutils-0.15.2 future-0.18.2 jmespath-0.10.0 joblib-0.17.0 numpy-1.19.4 packaging-20.7 parso-0.7.0 pika-0.13.1 py4j-0.10.9 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2020.4 pyzmq-20.0.0 requests-2.25.0 requests-toolbelt-0.9.1 s3transfer-0.3.3 scikit-learn-0.23.2 scipy-1.5.4 threadpoolctl-2.1.0 trafaret-1.2.0 urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "numpy",
                  "pyparsing",
                  "pytz",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Install needed packages (requirements.txt from the DR repo)\n",
        "! pip install -r mlops-examples/tracking_agents/python/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the MLOps Connected Client\n",
        "! pip install datarobot-mlops-connected-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YeWsEAlJD7Qk",
        "outputId": "13a2c009-909c-4931-b79d-753ba9a7d316"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datarobot-mlops-connected-client\n",
            "  Downloading datarobot_mlops_connected_client-7.3.8-py2.py3-none-any.whl (29 kB)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from datarobot-mlops-connected-client) (2.25.0)\n",
            "Requirement already satisfied: datarobot-mlops>=7.1 in /usr/local/lib/python3.7/dist-packages (from datarobot-mlops-connected-client) (8.0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datarobot-mlops-connected-client) (1.1.5)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.7/dist-packages (from datarobot-mlops>=7.1->datarobot-mlops-connected-client) (0.18.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from datarobot-mlops>=7.1->datarobot-mlops-connected-client) (2.8.1)\n",
            "Requirement already satisfied: boto3<2,>=1.11.4 in /usr/local/lib/python3.7/dist-packages (from datarobot-mlops>=7.1->datarobot-mlops-connected-client) (1.11.4)\n",
            "Requirement already satisfied: py4j<1,>=0.10.9.1 in /usr/local/lib/python3.7/dist-packages (from datarobot-mlops>=7.1->datarobot-mlops-connected-client) (0.10.9.3)\n",
            "Requirement already satisfied: datarobot in /usr/local/lib/python3.7/dist-packages (from datarobot-mlops>=7.1->datarobot-mlops-connected-client) (2.22.1)\n",
            "Requirement already satisfied: pika<1,>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from datarobot-mlops>=7.1->datarobot-mlops-connected-client) (0.13.1)\n",
            "Requirement already satisfied: deprecation<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from datarobot-mlops>=7.1->datarobot-mlops-connected-client) (2.1.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3<2,>=1.11.4->datarobot-mlops>=7.1->datarobot-mlops-connected-client) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.4 in /usr/local/lib/python3.7/dist-packages (from boto3<2,>=1.11.4->datarobot-mlops>=7.1->datarobot-mlops-connected-client) (1.14.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3<2,>=1.11.4->datarobot-mlops>=7.1->datarobot-mlops-connected-client) (0.10.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.7/dist-packages (from botocore<1.15.0,>=1.14.4->boto3<2,>=1.11.4->datarobot-mlops>=7.1->datarobot-mlops-connected-client) (0.15.2)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.7/dist-packages (from botocore<1.15.0,>=1.14.4->boto3<2,>=1.11.4->datarobot-mlops>=7.1->datarobot-mlops-connected-client) (1.25.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation<3,>=2.1.0->datarobot-mlops>=7.1->datarobot-mlops-connected-client) (20.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->datarobot-mlops>=7.1->datarobot-mlops-connected-client) (1.15.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 44.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datarobot-mlops-connected-client) (2.0.8)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 54.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datarobot-mlops-connected-client) (19.3.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 39.9 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datarobot-mlops-connected-client) (3.10.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->datarobot-mlops-connected-client) (2.10)\n",
            "Requirement already satisfied: pyyaml>=3.11 in /usr/local/lib/python3.7/dist-packages (from datarobot->datarobot-mlops>=7.1->datarobot-mlops-connected-client) (5.3.1)\n",
            "Requirement already satisfied: requests-toolbelt>=0.6 in /usr/local/lib/python3.7/dist-packages (from datarobot->datarobot-mlops>=7.1->datarobot-mlops-connected-client) (0.9.1)\n",
            "Requirement already satisfied: trafaret!=1.1.0,<2.0,>=0.7 in /usr/local/lib/python3.7/dist-packages (from datarobot->datarobot-mlops>=7.1->datarobot-mlops-connected-client) (1.2.0)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from datarobot->datarobot-mlops>=7.1->datarobot-mlops-connected-client) (0.6.0.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datarobot-mlops-connected-client) (2020.4)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->datarobot-mlops-connected-client) (1.19.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->datarobot-mlops-connected-client) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->datarobot-mlops-connected-client) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deprecation<3,>=2.1.0->datarobot-mlops>=7.1->datarobot-mlops-connected-client) (2.4.7)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, aiohttp, datarobot-mlops-connected-client\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datarobot-mlops-connected-client-7.3.8 frozenlist-1.2.0 multidict-5.2.0 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "datarobot"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J8kIl1NqX8-"
      },
      "source": [
        "### Downloading, Configuring and Installing the Agent \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7UQiTB70qX8_"
      },
      "outputs": [],
      "source": [
        "# DataRobot Python API client\n",
        "import datarobot as dr\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to DataRobot platform with python client. \n",
        "# using my config file in Google Drive. \n",
        "client = dr.Client(config_path='/content/drive/My Drive/Enablement/MLOps/drconfig.yaml')"
      ],
      "metadata": {
        "id": "QqOBDANFvST9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the tarball from the DR Cloud (HTTP request)\n",
        "mlops_agents_tb = client.get(\"mlopsInstaller\")"
      ],
      "metadata": {
        "id": "DTPdWmqWxP2h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yd0uA5WzqX8_"
      },
      "outputs": [],
      "source": [
        "# Write the tarball (HTTP response content) into a local file\n",
        "with open(\"mlops-examples/tracking_agents/python/mlops-agent.tar.gz\", \"wb\") as f:\n",
        "     f.write(mlops_agents_tb.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncompress the agent tarball into the root dir\n",
        "! tar -xf mlops-examples/tracking_agents/python/mlops-agent.tar.gz"
      ],
      "metadata": {
        "id": "vFZhMrQayelS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "reFijoG9qX9B",
        "outputId": "74d4ee84-cbe0-4664-d567-86debce4674f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datarobot_mlops_package-8.0.3\n",
            "8.0.3\n"
          ]
        }
      ],
      "source": [
        "# Obtain mlops package folder name and version\n",
        "with os.popen(\"ls /content\") as pipe:\n",
        "    for line in pipe:\n",
        "        if line.startswith('datarobot_mlops_package'):\n",
        "            mlops_package = line.strip()\n",
        "            version = line.strip()[-5:]\n",
        "print(mlops_package)\n",
        "print(version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lNFqCex1qX9C",
        "outputId": "387af201-504d-4fb2-a1f1-3a22254b5841",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Execute command and install mlops-agent\n",
        "os.system('pip install /content/{}/lib/datarobot_mlops-{}-py2.py3-none-any.whl'.format(mlops_package, version))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy my own MLOps Agent Conf from my Drive. \n",
        "# It contains MLOps URL, API Token and Spool Dir. \n",
        "os.system('cp /content/drive/My\\ Drive/Enablement/MLOps/mlops.agent.conf.yaml /content/{}/conf/mlops.agent.conf.yaml'.format(mlops_package))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed454f69-19a9-485c-b79e-5ab7ef16a31c",
        "id": "Ww7P43tI5joS"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read spool dir from yaml:\n",
        "import yaml\n",
        "with open('/content/{}/conf/mlops.agent.conf.yaml'.format(mlops_package)) as conf:\n",
        "      config_dict = yaml.load(conf, Loader=yaml.BaseLoader)\n",
        "spool_dir = config_dict.get('channelConfigs')[0].get('details').get('directory')\n",
        "print(spool_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YamMFn6sH3Vk",
        "outputId": "91bb7985-d29f-444b-bbf2-c386cc63d8e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tmp/ta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "w2BrSVCuqX9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3aace78-3c80-4c18-c88c-d777034dadf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Create the local spool dir\n",
        "os.system('mkdir -p {}'.format(spool_dir))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check\n",
        "! ls -la /content/tmp/ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrL4bVWX4frd",
        "outputId": "bc4bfc4c-ea17-48a5-b405-4fcc552bb96b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "drwxr-xr-x 2 root root 4096 Dec 31 10:48 .\n",
            "drwxr-xr-x 3 root root 4096 Dec 31 10:48 ..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WGoq143qX9E"
      },
      "source": [
        "### Start the agent "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "sWSQZPJrqX9F",
        "outputId": "6cf706d7-f735-4c50-89e3-2385ca98f8df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Start the agent in the local machine\n",
        "os.system('bash /content/{}/bin/start-agent.sh'.format(mlops_package))\n",
        "# ! bash /content/datarobot_mlops_package-8.0.3/bin/start-agent.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "4Vp98fYnqX9F",
        "outputId": "f930f0f9-b4fb-4d9e-e5cb-65c44ad5cfbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No DataRobot MLOps-Agent is currently running as a service.\n"
          ]
        }
      ],
      "source": [
        "# Shutdown - DON'T RUN THIS CELL, IT'S JUST SHOWING YOU HOW TO SHUTDOWN\n",
        "# ! bash datarobot_mlops_package-x.x.x/bin/stop-agent.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that it is running\n",
        "! bash /content/datarobot_mlops_package-8.0.3/bin/status-agent.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzJrWsG_7nfn",
        "outputId": "f62417f5-2d5c-4681-a843-71f652e0200f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataRobot MLOps-Agent is running as a service.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5325TblqX9F"
      },
      "source": [
        "### Create an MLOps Model Package for a model and deploy it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CFWIiFaqX9G"
      },
      "source": [
        "#### Train a simple RandomForestClassifier model to use for this example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1ZivfWoaqX9G",
        "outputId": "04d177c0-6562-4c18-944d-1b1dc4026e44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=2, n_estimators=10, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import csv\n",
        "import pytz\n",
        "import json\n",
        "import yaml\n",
        "import datetime\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "TRAINING_DATA = '/content/{}/examples/data/mlops-example-surgical-dataset.csv'.format(mlops_package)\n",
        "\n",
        "df = pd.read_csv(TRAINING_DATA)\n",
        "\n",
        "columns = list(df.columns)\n",
        "arr = df.to_numpy()\n",
        "\n",
        "np.random.shuffle(arr)\n",
        "\n",
        "split_ratio = 0.8\n",
        "prediction_threshold = 0.5\n",
        "\n",
        "train_data_len = int(arr.shape[0] * split_ratio)\n",
        "\n",
        "train_data = arr[:train_data_len, :-1]\n",
        "label = arr[:train_data_len, -1]\n",
        "test_data = arr[train_data_len:, :-1]\n",
        "test_df = df[train_data_len:]\n",
        "\n",
        "# train the model\n",
        "clf = RandomForestClassifier(n_estimators=10, max_depth=2, random_state=0)\n",
        "clf.fit(train_data, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2228Ca1CqX9G"
      },
      "source": [
        "#### Create empty deployment in DataRobot MLOps"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the MLOps client, create a new model package to represent the random forest model we just created.  This includes uploading the traning data and enabling data drift."
      ],
      "metadata": {
        "id": "iQ490qE3K-D0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MqGYhrKmqX9G",
        "outputId": "7a78b1a9-1e44-41af-975b-61712915790b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading training data - /content/datarobot_mlops_package-8.0.3/examples/data/mlops-example-surgical-dataset.csv. This may take some time...\n",
            "Training dataset uploaded. Catalog ID 61cee6926efb4af8fffee026.\n",
            "Create model package\n",
            "Deploy model package\n",
            "Enable feature drift\n",
            "\n",
            "Done.\n",
            "DEPLOYMENT_ID=61cee6c1693dfb0a76c6f518, MODEL_ID=61cee6c1ccf3698c174d7d69\n"
          ]
        }
      ],
      "source": [
        "from datarobot.mlops.mlops import MLOps\n",
        "# from datarobot.mlops.common.enums import OutputType\n",
        "from datarobot.mlops.connected.client import MLOpsClient\n",
        "from datarobot.mlops.common.exception import DRConnectedException\n",
        "from datarobot.mlops.constants import Constants\n",
        "\n",
        "# Read the model configuration info from the example.  This is used to create the model package.\n",
        "with open('/content/{}/examples/model_config/surgical_binary_classification.json'.format(mlops_package), \"r\") as f:\n",
        "    model_info = json.loads(f.read())\n",
        "model_info\n",
        "\n",
        "# Read the mlops connection info from the provided example \n",
        "with open('/content/{}/conf/mlops.agent.conf.yaml'.format(mlops_package)) as file:\n",
        "    # The FullLoader parameter handles the conversion from YAML\n",
        "    # scalar values to Python the dictionary format\n",
        "    agent_yaml_dict = yaml.load(file, Loader=yaml.FullLoader)\n",
        "\n",
        "MLOPS_URL = agent_yaml_dict['mlopsUrl']\n",
        "API_TOKEN = agent_yaml_dict['apiToken']\n",
        "\n",
        "# Create connected client\n",
        "mlops_connected_client = MLOpsClient(MLOPS_URL, API_TOKEN)\n",
        "\n",
        "# Add training_data to model configuration\n",
        "print(\"Uploading training data - {}. This may take some time...\".format(TRAINING_DATA))\n",
        "dataset_id = mlops_connected_client.upload_dataset(TRAINING_DATA)\n",
        "print(\"Training dataset uploaded. Catalog ID {}.\".format(dataset_id))\n",
        "model_info[\"datasets\"] = {\"trainingDataCatalogId\": dataset_id}\n",
        "\n",
        "# Create the model package\n",
        "print('Create model package')\n",
        "model_pkg_id = mlops_connected_client.create_model_package(model_info)\n",
        "model_pkg = mlops_connected_client.get_model_package(model_pkg_id)\n",
        "model_id = model_pkg[\"modelId\"]\n",
        "\n",
        "# Deploy the model package\n",
        "print('Deploy model package')\n",
        "\n",
        "# Give the deployment a name:\n",
        "DEPLOYMENT_NAME=\"[RAM] SkLearn Remote Model - Binary - \" + str(datetime.datetime.now())\n",
        "\n",
        "deployment_id = mlops_connected_client.deploy_model_package(model_pkg[\"id\"],\n",
        "                                                            DEPLOYMENT_NAME)\n",
        "\n",
        "# Enable data drift tracking\n",
        "print('Enable feature drift')\n",
        "enable_feature_drift = TRAINING_DATA is not None\n",
        "mlops_connected_client.update_deployment_settings(deployment_id, target_drift=True,\n",
        "                                                  feature_drift=enable_feature_drift)\n",
        "_ = mlops_connected_client.get_deployment_settings(deployment_id)\n",
        "\n",
        "print(\"\\nDone.\")\n",
        "print(\"DEPLOYMENT_ID=%s, MODEL_ID=%s\" % (deployment_id, model_id))\n",
        "\n",
        "DEPLOYMENT_ID = deployment_id\n",
        "MODEL_ID = model_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGqjNv7iqX9H"
      },
      "source": [
        "#### Call the external model's predict fuction and send prediction data to MLOps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can find Deployment and Model ID under `Deployments` --> `Predictions` --> `Monitoring` Tab. The rest of the code can stay as it is."
      ],
      "metadata": {
        "id": "P6mDtS-COFd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# global variables in case runtime is restarted\n",
        "if 'DEPLOYMENT_ID' not in globals(): \n",
        "  DEPLOYMENT_ID = '61cee6c1693dfb0a76c6f518'\n",
        "if 'MODEL_ID' not in globals():\n",
        "  MODEL_ID = '61cee6c1ccf3698c174d7d69'"
      ],
      "metadata": {
        "id": "syCBfT_CO3eB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import time\n",
        "import random\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "xTJKAbn9Q2IJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary classifier\n",
        "CLASS_NAMES = [\"1\", \"0\"]\n",
        "\n",
        "# Spool directory path must match the Monitoring Agent path configured by admin.\n",
        "SPOOL_DIR = spool_dir\n",
        "\n",
        "# Actuals dataset\n",
        "ACTUALS_OUTPUT_FILE = 'actuals.csv'"
      ],
      "metadata": {
        "id": "ACJeFQA3RCR_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLOps Agent init\n",
        "mlops = MLOps() \\\n",
        "  .set_deployment_id(DEPLOYMENT_ID) \\\n",
        "  .set_model_id(MODEL_ID) \\\n",
        "  .set_filesystem_spooler(SPOOL_DIR) \\\n",
        "  .init()"
      ],
      "metadata": {
        "id": "OZq5nbSsRMdl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "start_time = time.time()\n",
        "predictions = clf.predict_proba(test_data).tolist()\n",
        "num_predictions = len(predictions)\n",
        "end_time = time.time()\n",
        "\n",
        "# Get assocation id's for the predictions so we can track them with the actuals\n",
        "def _generate_unique_association_ids(num_samples):\n",
        "  ts = time.time()\n",
        "  return [\"x_{}_{}\".format(ts, i) for i in range(num_samples)]\n",
        "\n",
        "association_ids = _generate_unique_association_ids(len(test_data))"
      ],
      "metadata": {
        "id": "AdSEF6nnSLV7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLOPS: report the number of predictions in the request and the execution time.\n",
        "mlops.report_deployment_stats(num_predictions, end_time - start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAiDwb7-SmTg",
        "outputId": "837d581a-ccc7-4943-82de-472499f0e1d6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLOPS: report the predictions data: features, predictions, class_names\n",
        "mlops.report_predictions_data(features_df=test_df, \n",
        "                              predictions=predictions, \n",
        "                              class_names=CLASS_NAMES,\n",
        "                              association_ids=association_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfvyNc_CSs5d",
        "outputId": "aef980df-19ca-410c-b865-710d8addcd5d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def write_actuals_file(out_filename, test_data_labels, association_ids):\n",
        "        \"\"\"\n",
        "         Generate a CSV file with the association ids and labels, this example\n",
        "         uses a dataset that has labels already.\n",
        "         In a real use case actuals (labels) will show after prediction is done.\n",
        "\n",
        "        :param out_filename:      name of csv file\n",
        "        :param test_data_labels:  actual values (labels)\n",
        "        :param association_ids:   association id list used for predictions\n",
        "        \"\"\"\n",
        "        with open(out_filename, mode=\"w\") as actuals_csv_file:\n",
        "            writer = csv.writer(actuals_csv_file, delimiter=\",\")\n",
        "            writer.writerow(\n",
        "                [\n",
        "                    Constants.ACTUALS_ASSOCIATION_ID_KEY,\n",
        "                    Constants.ACTUALS_VALUE_KEY,\n",
        "                    Constants.ACTUALS_TIMESTAMP_KEY\n",
        "                ]\n",
        "            )\n",
        "            tz = pytz.timezone(\"America/Los_Angeles\")\n",
        "            for (association_id, label) in zip(association_ids, test_data_labels):\n",
        "                actual_timestamp = datetime.datetime.now().replace(tzinfo=tz).isoformat()\n",
        "                writer.writerow([association_id, \"1\" if label else \"0\", actual_timestamp])\n"
      ],
      "metadata": {
        "id": "NAt2GLTqTeDJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_column_name = columns[len(columns) - 1]\n",
        "target_values = []\n",
        "orig_labels = test_df[target_column_name].tolist()\n",
        "\n",
        "# Write csv file with labels and association Id, when output file is provided\n",
        "write_actuals_file(ACTUALS_OUTPUT_FILE, orig_labels, association_ids)\n",
        "\n",
        "print(\"Wrote actuals file: %s\" % ACTUALS_OUTPUT_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I35Ap2zhS9Qg",
        "outputId": "2614c03e-2242-444d-e115-dfc633a9e0fe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote actuals file: actuals.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XUThj6VSqX9H"
      },
      "outputs": [],
      "source": [
        "# MLOPS: release MLOps resources when finished.\n",
        "mlops.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ1XnOl6qX9I"
      },
      "source": [
        "### Upload actuals back to MLOps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iGOYMxX8qX9I"
      },
      "outputs": [],
      "source": [
        "def _get_correct_actual_value(deployment_type, value):\n",
        "    if deployment_type == \"Regression\":\n",
        "        return float(value)\n",
        "    return str(value)\n",
        "\n",
        "def _get_correct_flag_value(value_str):\n",
        "    if value_str == \"True\":\n",
        "        return True\n",
        "    return False\n",
        "    \n",
        "def upload_actuals():\n",
        "    print(\"Connect MLOps client\")\n",
        "    mlops_connected_client = MLOpsClient(MLOPS_URL, API_TOKEN)\n",
        "    deployment_type = mlops_connected_client.get_deployment_type(DEPLOYMENT_ID)\n",
        "\n",
        "    actuals = []\n",
        "    with open(ACTUALS_OUTPUT_FILE, mode=\"r\") as actuals_csv_file:\n",
        "        reader = csv.DictReader(actuals_csv_file)\n",
        "        for row in reader:\n",
        "            actual = {}\n",
        "            for key, value in row.items():\n",
        "                if key == Constants.ACTUALS_WAS_ACTED_ON_KEY:\n",
        "                    value = _get_correct_flag_value(value)\n",
        "                if key == Constants.ACTUALS_VALUE_KEY:\n",
        "                    value = _get_correct_actual_value(deployment_type, value)\n",
        "                actual[key] = value\n",
        "            actuals.append(actual)\n",
        "\n",
        "            if len(actuals) == 10000:\n",
        "                mlops_connected_client.submit_actuals(DEPLOYMENT_ID, actuals)\n",
        "                actuals = []\n",
        "\n",
        "    # Submit the actuals\n",
        "    print(\"Submit actuals\")\n",
        "    mlops_connected_client.submit_actuals(DEPLOYMENT_ID, actuals)\n",
        "    \n",
        "    print(\"Done.\")    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upload_actuals()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElrPo1_bUr5p",
        "outputId": "3ee8e5cb-d06d-462d-a3df-6d476c9b879e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connect MLOps client\n",
            "Submit actuals\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpV0YjIZqX9I"
      },
      "source": [
        "### Stop the mlops service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "e-v9Z57PqX9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a250e460-063e-4196-9a83-ab851e00d4b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataRobot MLOps-Agent shutdown done.\n"
          ]
        }
      ],
      "source": [
        "! bash /content/datarobot_mlops_package-8.0.3/bin/stop-agent.sh #Change version based on the downloaded file"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "ML_Ops_Cert_Main_Script.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}